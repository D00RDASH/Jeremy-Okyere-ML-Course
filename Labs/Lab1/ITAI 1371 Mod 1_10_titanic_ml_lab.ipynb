{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ba63662d",
      "metadata": {},
      "source": [
        "# üö¢ Comprehensive ML Lab Tutorial: Modules 1-10\n",
        "## Predicting Titanic Survival\n",
        "\n",
        "**Course:** ITAI 1371 - Introduction to Machine Learning  \n",
        "**Purpose:** Catch-up lab covering fundamental concepts from Modules 1-10  \n",
        "**Week:** 11\n",
        "\n",
        "---\n",
        "\n",
        "### About This Lab\n",
        "\n",
        "Welcome! In this lab, we'll learn machine learning concepts using the famous **Titanic dataset**. On April 15, 1912, the RMS Titanic sank after colliding with an iceberg. While there were not enough lifeboats for everyone, some people were more likely to survive than others.\n",
        "\n",
        "We'll use machine learning to discover patterns in the data and predict who survived based on features like:\n",
        "- Age and gender\n",
        "- Passenger class (1st, 2nd, 3rd)\n",
        "- Ticket fare\n",
        "- Number of family members aboard\n",
        "- Port of embarkation\n",
        "\n",
        "This real-world dataset makes learning ML concepts more engaging and relatable!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04e95716",
      "metadata": {},
      "source": [
        "---\n",
        "## Module 1: Welcome, Introduction, and What is Machine Learning?\n",
        "\n",
        "Machine learning enables computers to learn patterns from data and make predictions without being explicitly programmed. Instead of writing rules like \"if age < 10, then survived\", we let the computer discover these patterns automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06a2d387",
      "metadata": {},
      "source": [
        "### What is Machine Learning?\n",
        "\n",
        "**Traditional Programming:**\n",
        "- You write explicit rules: \"If passenger is female AND in 1st class, predict survival\"\n",
        "- Rules are rigid and hard to maintain\n",
        "- Difficult to handle complex patterns\n",
        "\n",
        "**Machine Learning:**\n",
        "- You provide examples of passengers and whether they survived\n",
        "- The algorithm learns patterns automatically\n",
        "- Can discover complex relationships you might miss\n",
        "- Adapts as new data becomes available\n",
        "\n",
        "**Example:** Instead of manually coding rules for Titanic survival, ML can discover that women and children in higher classes had better survival rates, along with many other subtle patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e32a7659",
      "metadata": {},
      "source": [
        "### ML vs. AI vs. Traditional Programming\n",
        "\n",
        "- **Artificial Intelligence (AI):** The broad goal of creating intelligent machines (e.g., self-driving cars, voice assistants)\n",
        "\n",
        "- **Machine Learning (ML):** A subset of AI focused on learning from data (e.g., predicting survival, recommending movies)\n",
        "\n",
        "- **Deep Learning:** A subset of ML using neural networks with many layers (e.g., image recognition, language translation)\n",
        "\n",
        "- **Traditional Programming:** Writing explicit step-by-step instructions\n",
        "\n",
        "**Key Difference:** Traditional programming uses data + rules ‚Üí answers. Machine learning uses data + answers ‚Üí rules."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "576084bd",
      "metadata": {},
      "source": [
        "### Key Concepts in Machine Learning\n",
        "\n",
        "- **Algorithm:** The method used to learn patterns (e.g., decision trees, logistic regression)\n",
        "\n",
        "- **Model:** The result after training - it contains learned patterns and can make predictions\n",
        "\n",
        "- **Training:** Feeding historical data to an algorithm so it learns patterns\n",
        "\n",
        "- **Inference/Prediction:** Using the trained model on new data to make predictions\n",
        "\n",
        "- **Features:** Input variables used for predictions (age, gender, class, fare)\n",
        "\n",
        "- **Labels/Target:** What we're trying to predict (survived or not)\n",
        "\n",
        "- **Dataset:** Collection of examples with features and labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b737fc34",
      "metadata": {},
      "source": [
        "### Types of Machine Learning\n",
        "\n",
        "#### 1. **Supervised Learning** üéØ\n",
        "Learn from labeled data (we know the answers).\n",
        "\n",
        "**Titanic Example:** We have passenger data AND we know who survived. The model learns the relationship between passenger features and survival.\n",
        "\n",
        "**Other Examples:**\n",
        "- Email spam detection (labeled as spam/not spam)\n",
        "- House price prediction (we know actual prices)\n",
        "- Disease diagnosis (labeled as positive/negative)\n",
        "\n",
        "#### 2. **Unsupervised Learning** üîç\n",
        "Find patterns in unlabeled data (no predefined answers).\n",
        "\n",
        "**Titanic Example:** Group passengers into clusters based on similarities (age, fare, class) without knowing survival outcomes.\n",
        "\n",
        "**Other Examples:**\n",
        "- Customer segmentation\n",
        "- Anomaly detection\n",
        "- Topic discovery in documents\n",
        "\n",
        "#### 3. **Reinforcement Learning** üéÆ\n",
        "Learn by trial and error through rewards and penalties.\n",
        "\n",
        "**Examples:**\n",
        "- Game-playing AI (chess, Go)\n",
        "- Robot navigation\n",
        "- Autonomous vehicles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e4e8fa3",
      "metadata": {},
      "source": [
        "### üìù Knowledge Check - Module 1\n",
        "\n",
        "**Question 1:** In the Titanic dataset, what are the features and what is the label?\n",
        "\n",
        "**Question 2:** Why is machine learning better than traditional programming for predicting Titanic survival?\n",
        "\n",
        "**Question 3:** Is predicting Titanic survival a supervised or unsupervised learning problem? Why?\n",
        "\n",
        "**Question 4:** Give an example of how you might use unsupervised learning with the Titanic dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f75c67a6",
      "metadata": {},
      "source": [
        "---\n",
        "## Module 2: Tools Used in Machine Learning\n",
        "\n",
        "Let's set up our environment and import the essential libraries for ML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27cbbfe6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install necessary libraries (uncomment if needed)\n",
        "# !pip install scikit-learn pandas numpy matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a58d36d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import essential libraries\n",
        "import pandas as pd  # Data manipulation and analysis\n",
        "import numpy as np  # Numerical operations\n",
        "import matplotlib.pyplot as plt  # Basic plotting\n",
        "import seaborn as sns  # Statistical visualizations\n",
        "from sklearn.model_selection import train_test_split  # Split data\n",
        "from sklearn.metrics import accuracy_score, classification_report  # Evaluation\n",
        "\n",
        "# Set visualization style for better-looking plots\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "print(\"‚úì Libraries imported successfully!\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7a9369a",
      "metadata": {},
      "source": [
        "### Essential Python Libraries for ML\n",
        "\n",
        "#### **Scikit-learn** (sklearn)\n",
        "Your ML toolkit with algorithms for classification, regression, clustering, and more.\n",
        "\n",
        "#### **Pandas**\n",
        "Handles tabular data (like spreadsheets) with DataFrames. Perfect for loading CSVs and data manipulation.\n",
        "\n",
        "#### **NumPy**\n",
        "Fast numerical operations on arrays and matrices. Foundation for scientific computing in Python.\n",
        "\n",
        "#### **Matplotlib**\n",
        "Create all types of visualizations: line plots, scatter plots, histograms, etc.\n",
        "\n",
        "#### **Seaborn**\n",
        "Built on Matplotlib, provides beautiful statistical visualizations with less code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fadf7bd9",
      "metadata": {},
      "source": [
        "### Loading the Titanic Dataset\n",
        "\n",
        "Let's load our dataset and take a first look at it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2154e4a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Titanic dataset\n",
        "# We'll create it from scratch for this lab\n",
        "titanic_url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "\n",
        "try:\n",
        "    # Try to load from URL\n",
        "    df = pd.read_csv(titanic_url)\n",
        "    print(\"‚úì Dataset loaded from URL\")\n",
        "except:\n",
        "    # If URL fails, create a sample dataset\n",
        "    print(\"Creating sample dataset...\")\n",
        "    # This is a fallback - in practice, students would load from URL or file\n",
        "    \n",
        "print(f\"\\nDataset shape: {df.shape[0]} passengers, {df.shape[1]} columns\")\n",
        "print(\"\\nFirst 5 passengers:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb63435",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display column information\n",
        "print(\"\\nColumn Information:\")\n",
        "print(\"=\"*60)\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Column Descriptions:\")\n",
        "print(\"=\"*60)\n",
        "print(\"PassengerId: Unique ID for each passenger\")\n",
        "print(\"Survived: 0 = No, 1 = Yes (THIS IS WHAT WE WANT TO PREDICT)\")\n",
        "print(\"Pclass: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\")\n",
        "print(\"Name: Passenger name\")\n",
        "print(\"Sex: Male or Female\")\n",
        "print(\"Age: Age in years\")\n",
        "print(\"SibSp: Number of siblings/spouses aboard\")\n",
        "print(\"Parch: Number of parents/children aboard\")\n",
        "print(\"Ticket: Ticket number\")\n",
        "print(\"Fare: Passenger fare in British pounds\")\n",
        "print(\"Cabin: Cabin number\")\n",
        "print(\"Embarked: Port of embarkation (C=Cherbourg, Q=Queenstown, S=Southampton)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa2f0798",
      "metadata": {},
      "source": [
        "### üìù Knowledge Check - Module 2\n",
        "\n",
        "**Question 1:** What library would you use to load a CSV file into Python?\n",
        "\n",
        "**Question 2:** In the Titanic dataset, which column is our target variable (what we want to predict)?\n",
        "\n",
        "**Question 3:** How many passengers are in the dataset? How many features do we have?\n",
        "\n",
        "**Question 4:** Why is it useful to use Jupyter Notebooks for ML projects?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bbd5027",
      "metadata": {},
      "source": [
        "---\n",
        "## Module 3: Machine Learning Workflow and Types of Learning\n",
        "\n",
        "Every ML project follows a similar workflow. Let's understand the process and build our first simple model!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0984305",
      "metadata": {},
      "source": [
        "### The End-to-End ML Lifecycle\n",
        "\n",
        "1. **Problem Definition** üìã  \n",
        "   *Question: Can we predict who survived the Titanic disaster?*\n",
        "\n",
        "2. **Data Collection** üìä  \n",
        "   *We have historical passenger data with survival outcomes*\n",
        "\n",
        "3. **Data Preparation** üßπ  \n",
        "   *Clean data, handle missing values, encode categories*\n",
        "\n",
        "4. **Exploratory Data Analysis (EDA)** üîç  \n",
        "   *Understand patterns: Did women survive more? What about children?*\n",
        "\n",
        "5. **Feature Engineering** ‚öôÔ∏è  \n",
        "   *Create new features: family size, title from name*\n",
        "\n",
        "6. **Model Selection** üéØ  \n",
        "   *Choose appropriate algorithms*\n",
        "\n",
        "7. **Model Training** üèãÔ∏è  \n",
        "   *Train the model on historical data*\n",
        "\n",
        "8. **Model Evaluation** üìà  \n",
        "   *Test on unseen data, check accuracy*\n",
        "\n",
        "9. **Hyperparameter Tuning** üéõÔ∏è  \n",
        "   *Optimize model settings*\n",
        "\n",
        "10. **Deployment** üöÄ  \n",
        "    *Use the model in real applications*\n",
        "\n",
        "**Remember:** This is iterative! You'll go back and forth between steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6c91d7a",
      "metadata": {},
      "source": [
        "### Understanding Data Types in Our Dataset\n",
        "\n",
        "#### **Categorical Data** (Categories/Groups)\n",
        "- **Nominal:** No order (e.g., Sex: male/female; Embarked: C/Q/S)\n",
        "- **Ordinal:** Has order (e.g., Pclass: 1st > 2nd > 3rd)\n",
        "\n",
        "#### **Numerical Data** (Numbers)\n",
        "- **Discrete:** Countable (e.g., SibSp: 0, 1, 2, 3...)\n",
        "- **Continuous:** Any value in range (e.g., Age: 22.5, 35.0, Fare: 7.25, 71.28)\n",
        "\n",
        "#### **Text Data**\n",
        "- Name, Ticket, Cabin (requires special handling)\n",
        "\n",
        "**Why does this matter?** Different data types require different preprocessing techniques!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71753de7",
      "metadata": {},
      "source": [
        "### Simple Classifier Example\n",
        "\n",
        "Let's build a quick baseline model to predict survival!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2750d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for a simple model\n",
        "# We'll use just a few features to start\n",
        "\n",
        "# Select features (X) and target (y)\n",
        "features = ['Pclass', 'Sex', 'Age', 'Fare']\n",
        "target = 'Survived'\n",
        "\n",
        "# Create a copy of the data with selected columns\n",
        "df_simple = df[features + [target]].copy()\n",
        "\n",
        "# Handle missing values (simple approach for now)\n",
        "df_simple['Age'].fillna(df_simple['Age'].median(), inplace=True)\n",
        "df_simple['Fare'].fillna(df_simple['Fare'].median(), inplace=True)\n",
        "\n",
        "# Convert Sex to numbers (0=female, 1=male)\n",
        "df_simple['Sex'] = df_simple['Sex'].map({'female': 0, 'male': 1})\n",
        "\n",
        "# Remove any remaining rows with missing values\n",
        "df_simple.dropna(inplace=True)\n",
        "\n",
        "print(f\"Prepared dataset: {df_simple.shape[0]} passengers, {len(features)} features\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df_simple.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d7abfc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split features (X) and target (y)\n",
        "X = df_simple[features].values\n",
        "y = df_simple[target].values\n",
        "\n",
        "print(f\"Features (X) shape: {X.shape}\")\n",
        "print(f\"Target (y) shape: {y.shape}\")\n",
        "print(f\"\\nSurvival rate: {y.mean():.1%} survived, {1-y.mean():.1%} died\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8fdd3cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split into training and testing sets\n",
        "# 70% for training, 30% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.3,  # 30% for testing\n",
        "    random_state=42  # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Training set: {len(X_train)} passengers\")\n",
        "print(f\"Testing set: {len(X_test)} passengers\")\n",
        "print(f\"\\nWhy split? We train on one set and test on another to see if the model generalizes!\")\n",
        "print(f\"If we tested on training data, we couldn't tell if it truly learned or just memorized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca246c9a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a simple Decision Tree classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create the model\n",
        "model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"‚úì Model trained!\")\n",
        "print(f\"\\nThe model learned patterns from {len(X_train)} passengers.\")\n",
        "print(f\"Now let's see how well it predicts survival for {len(X_test)} unseen passengers...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c0596f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.1%}\")\n",
        "print(f\"\\nThis means the model correctly predicted survival for {accuracy:.1%} of test passengers.\")\n",
        "print(f\"\\nFirst 10 predictions:\")\n",
        "print(f\"Predicted: {y_pred[:10]}\")\n",
        "print(f\"Actual:    {y_test[:10]}\")\n",
        "print(f\"\\n0 = Did not survive, 1 = Survived\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91bc4318",
      "metadata": {},
      "source": [
        "### üìù Knowledge Check - Module 3\n",
        "\n",
        "**Question 1:** What are the main stages of the ML lifecycle? Why is it iterative?\n",
        "\n",
        "**Question 2:** In the Titanic dataset, classify each feature as categorical or numerical:\n",
        "- Sex\n",
        "- Age  \n",
        "- Pclass\n",
        "- Fare\n",
        "\n",
        "**Question 3:** Why do we split data into training and testing sets? What would happen if we evaluated on training data?\n",
        "\n",
        "**Question 4:** Our simple model achieved around 78% accuracy. What does this mean? Is this good?\n",
        "\n",
        "**Question 5:** Looking at the first 10 predictions, how many did the model get right?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46836afd",
      "metadata": {},
      "source": [
        "---\n",
        "## Module 4: Working with Data & Exploratory Data Analysis (EDA)\n",
        "\n",
        "EDA is detective work! We explore the data to understand patterns, find problems, and generate insights that will guide our modeling decisions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af3e4fb4",
      "metadata": {},
      "source": [
        "### Why EDA Matters for Titanic\n",
        "\n",
        "**Questions we want to answer:**\n",
        "- Did women really have better survival rates? (\"Women and children first!\")\n",
        "- Did wealthier passengers (1st class) survive more?\n",
        "- What was the age distribution of survivors?\n",
        "- Were there missing values we need to handle?\n",
        "- Are there outliers in fare prices?\n",
        "\n",
        "Let's investigate!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23c6d32",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reload the full dataset for EDA\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
        "\n",
        "print(\"Dataset Overview:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total passengers: {len(df)}\")\n",
        "print(f\"Total features: {df.shape[1]}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3baa921",
      "metadata": {},
      "source": [
        "### Data Quality Checks\n",
        "\n",
        "Before analyzing, we need to check for common data quality issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "079967df",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing Values:\")\n",
        "print(\"=\"*60)\n",
        "missing = df.isnull().sum()\n",
        "missing_pct = (missing / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing,\n",
        "    'Percentage': missing_pct\n",
        "})\n",
        "print(missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False))\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è Key findings:\")\n",
        "print(\"- Cabin: 77% missing (might need to drop this feature)\")\n",
        "print(\"- Age: 20% missing (we'll need to impute)\")\n",
        "print(\"- Embarked: Only 2 missing (easy to handle)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a897e6df",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for duplicates\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"Duplicate rows: {duplicates}\")\n",
        "if duplicates == 0:\n",
        "    print(\"‚úì No duplicates found - data looks clean!\")\n",
        "\n",
        "# Check data types\n",
        "print(\"\\nData Types:\")\n",
        "print(\"=\"*60)\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eae9e6d",
      "metadata": {},
      "source": [
        "### Summary Statistics\n",
        "\n",
        "Let's get a statistical overview of our numerical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b94d0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics\n",
        "print(\"Summary Statistics:\")\n",
        "print(\"=\"*60)\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nKey Insights:\")\n",
        "print(f\"- Average age: {df['Age'].mean():.1f} years (median: {df['Age'].median():.1f})\")\n",
        "print(f\"- Average fare: ¬£{df['Fare'].mean():.2f} (median: ¬£{df['Fare'].median():.2f})\")\n",
        "print(f\"- Fare range: ¬£{df['Fare'].min():.2f} to ¬£{df['Fare'].max():.2f} (huge variation!)\")\n",
        "print(f\"- Most passengers traveled alone (avg SibSp: {df['SibSp'].mean():.2f}, Parch: {df['Parch'].mean():.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39c90411",
      "metadata": {},
      "source": [
        "### Survival Analysis\n",
        "\n",
        "Let's answer the big question: Who survived?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fed39ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overall survival rate\n",
        "survival_rate = df['Survived'].mean()\n",
        "print(f\"Overall Survival Rate: {survival_rate:.1%}\")\n",
        "print(f\"Survived: {df['Survived'].sum()} passengers\")\n",
        "print(f\"Died: {len(df) - df['Survived'].sum()} passengers\")\n",
        "print(f\"\\nüò¢ Only about 38% of passengers survived the disaster.\")\n",
        "\n",
        "# Visualize survival\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "survival_counts = df['Survived'].value_counts()\n",
        "colors = ['#ff6b6b', '#51cf66']\n",
        "ax.bar(['Died', 'Survived'], survival_counts.values, color=colors, edgecolor='black', linewidth=2)\n",
        "ax.set_ylabel('Number of Passengers', fontsize=12)\n",
        "ax.set_title('Titanic Survival Distribution', fontsize=14, fontweight='bold')\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(survival_counts.values):\n",
        "    ax.text(i, v + 10, str(v), ha='center', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26b46db1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Survival by Gender\n",
        "print(\"\\nSurvival by Gender:\")\n",
        "print(\"=\"*60)\n",
        "gender_survival = df.groupby('Sex')['Survived'].agg(['sum', 'count', 'mean'])\n",
        "gender_survival.columns = ['Survived', 'Total', 'Survival Rate']\n",
        "gender_survival['Survival Rate'] = gender_survival['Survival Rate'].apply(lambda x: f\"{x:.1%}\")\n",
        "print(gender_survival)\n",
        "\n",
        "print(\"\\nüë© Women had a MUCH higher survival rate!\")\n",
        "print(\"This supports the 'women and children first' policy.\")\n",
        "\n",
        "# Visualize\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "df.groupby(['Sex', 'Survived']).size().unstack().plot(kind='bar', ax=ax, color=['#ff6b6b', '#51cf66'], edgecolor='black')\n",
        "ax.set_xlabel('Gender', fontsize=12)\n",
        "ax.set_ylabel('Number of Passengers', fontsize=12)\n",
        "ax.set_title('Survival by Gender', fontsize=14, fontweight='bold')\n",
        "ax.set_xticklabels(['Female', 'Male'], rotation=0)\n",
        "ax.legend(['Died', 'Survived'])\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "927b7b11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Survival by Passenger Class\n",
        "print(\"\\nSurvival by Passenger Class:\")\n",
        "print(\"=\"*60)\n",
        "class_survival = df.groupby('Pclass')['Survived'].agg(['sum', 'count', 'mean'])\n",
        "class_survival.columns = ['Survived', 'Total', 'Survival Rate']\n",
        "class_survival['Survival Rate'] = class_survival['Survival Rate'].apply(lambda x: f\"{x:.1%}\")\n",
        "print(class_survival)\n",
        "\n",
        "print(\"\\nüí∞ Clear pattern: Higher class = Higher survival rate\")\n",
        "print(\"1st class passengers had better access to lifeboats.\")\n",
        "\n",
        "# Visualize\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "df.groupby(['Pclass', 'Survived']).size().unstack().plot(kind='bar', ax=ax, color=['#ff6b6b', '#51cf66'], edgecolor='black')\n",
        "ax.set_xlabel('Passenger Class', fontsize=12)\n",
        "ax.set_ylabel('Number of Passengers', fontsize=12)\n",
        "ax.set_title('Survival by Passenger Class', fontsize=14, fontweight='bold')\n",
        "ax.set_xticklabels(['1st Class', '2nd Class', '3rd Class'], rotation=0)\n",
        "ax.legend(['Died', 'Survived'])\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b17aaf38",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Age distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Histogram of ages\n",
        "axes[0].hist(df['Age'].dropna(), bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "axes[0].set_xlabel('Age (years)', fontsize=12)\n",
        "axes[0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0].set_title('Age Distribution of Passengers', fontsize=14, fontweight='bold')\n",
        "axes[0].axvline(df['Age'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"Age\"].mean():.1f}')\n",
        "axes[0].legend()\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Age by survival\n",
        "df[df['Survived']==0]['Age'].dropna().hist(bins=30, alpha=0.5, label='Died', ax=axes[1], color='red', edgecolor='black')\n",
        "df[df['Survived']==1]['Age'].dropna().hist(bins=30, alpha=0.5, label='Survived', ax=axes[1], color='green', edgecolor='black')\n",
        "axes[1].set_xlabel('Age (years)', fontsize=12)\n",
        "axes[1].set_ylabel('Frequency', fontsize=12)\n",
        "axes[1].set_title('Age Distribution by Survival', fontsize=14, fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüë∂ Children (young ages) seem to have better survival rates.\")\n",
        "print(\"This aligns with 'women and children first' policy.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb6a61ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation heatmap\n",
        "# Select only numerical columns\n",
        "numerical_cols = ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "corr_matrix = df[numerical_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, square=True, \n",
        "            linewidths=1, cbar_kws={\"shrink\": 0.8}, fmt='.2f')\n",
        "plt.title('Correlation Matrix of Titanic Features', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey Correlations with Survival:\")\n",
        "print(\"=\"*60)\n",
        "survival_corr = corr_matrix['Survived'].sort_values(ascending=False)\n",
        "for feature, corr in survival_corr.items():\n",
        "    if feature != 'Survived':\n",
        "        direction = \"positive\" if corr > 0 else \"negative\"\n",
        "        strength = \"strong\" if abs(corr) > 0.3 else \"moderate\" if abs(corr) > 0.1 else \"weak\"\n",
        "        print(f\"{feature:12s}: {corr:+.3f} ({strength} {direction})\")\n",
        "\n",
        "print(\"\\nüìä Insights:\")\n",
        "print(\"- Fare has positive correlation: higher fare ‚Üí better survival\")\n",
        "print(\"- Pclass has negative correlation: higher class number (3rd) ‚Üí worse survival\")\n",
        "print(\"- Sex (when encoded) would show strong correlation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a34e926f",
      "metadata": {},
      "source": [
        "### üìù Knowledge Check - Module 4\n",
        "\n",
        "**Question 1:** What percentage of passengers survived? Is this balanced or imbalanced?\n",
        "\n",
        "**Question 2:** Which gender had a higher survival rate? By approximately how much?\n",
        "\n",
        "**Question 3:** Did passenger class affect survival? What does this tell us about the disaster?\n",
        "\n",
        "**Question 4:** Which features have missing values? Which one has the most missing data?\n",
        "\n",
        "**Question 5:** Looking at the correlation matrix, which numerical feature has the strongest relationship with survival?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ab9467",
      "metadata": {},
      "source": [
        "---\n",
        "## Module 5: Data Preparation & Feature Engineering\n",
        "\n",
        "Raw data is rarely ready for modeling. We need to clean it, handle missing values, encode categories, and create new features. This step often makes the biggest difference in model performance!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0accaec",
      "metadata": {},
      "source": [
        "### Handling Missing Values\n",
        "\n",
        "Remember from EDA:\n",
        "- Age: 20% missing\n",
        "- Cabin: 77% missing  \n",
        "- Embarked: 2 missing\n",
        "\n",
        "Let's handle each strategically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d8189b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a working copy\n",
        "df_prep = df.copy()\n",
        "\n",
        "print(\"Missing values before handling:\")\n",
        "print(df_prep.isnull().sum()[df_prep.isnull().sum() > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1748b620",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Strategy 1: Drop Cabin (too many missing)\n",
        "df_prep.drop('Cabin', axis=1, inplace=True)\n",
        "print(\"‚úì Dropped 'Cabin' column (77% missing)\")\n",
        "\n",
        "# Strategy 2: Fill Age with median\n",
        "median_age = df_prep['Age'].median()\n",
        "df_prep['Age'].fillna(median_age, inplace=True)\n",
        "print(f\"‚úì Filled missing Age with median: {median_age} years\")\n",
        "\n",
        "# Strategy 3: Fill Embarked with mode (most common)\n",
        "mode_embarked = df_prep['Embarked'].mode()[0]\n",
        "df_prep['Embarked'].fillna(mode_embarked, inplace=True)\n",
        "print(f\"‚úì Filled missing Embarked with mode: {mode_embarked}\")\n",
        "\n",
        "print(\"\\nMissing values after handling:\")\n",
        "print(df_prep.isnull().sum().sum())\n",
        "print(\"‚úì All missing values handled!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c0b4f0",
      "metadata": {},
      "source": [
        "### Encoding Categorical Variables\n",
        "\n",
        "Machine learning models need numbers, not text. Let's convert categorical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f41ddcc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode Sex: female=0, male=1\n",
        "df_prep['Sex_encoded'] = df_prep['Sex'].map({'female': 0, 'male': 1})\n",
        "print(\"Sex encoding:\")\n",
        "print(df_prep[['Sex', 'Sex_encoded']].drop_duplicates())\n",
        "\n",
        "# One-hot encode Embarked\n",
        "df_prep = pd.get_dummies(df_prep, columns=['Embarked'], prefix='Embarked', drop_first=True)\n",
        "print(\"\\n‚úì One-hot encoded Embarked (C, Q, S)\")\n",
        "print(\"New columns:\", [col for col in df_prep.columns if 'Embarked' in col])\n",
        "\n",
        "print(\"\\nWhy drop_first=True?\")\n",
        "print(\"If Embarked_Q=0 and Embarked_S=0, we know it's Embarked_C.\")\n",
        "print(\"This avoids redundancy and multicollinearity.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcb58d7e",
      "metadata": {},
      "source": [
        "### Feature Scaling\n",
        "\n",
        "Features like Age (0-80) and Fare (0-500) have very different scales. Let's standardize them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38bc02b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Select numerical features to scale\n",
        "features_to_scale = ['Age', 'Fare']\n",
        "\n",
        "print(\"Before scaling:\")\n",
        "print(df_prep[features_to_scale].describe())\n",
        "\n",
        "# Create scaler and fit_transform\n",
        "scaler = StandardScaler()\n",
        "df_prep[features_to_scale] = scaler.fit_transform(df_prep[features_to_scale])\n",
        "\n",
        "print(\"\\nAfter scaling (standardization):\")\n",
        "print(df_prep[features_to_scale].describe())\n",
        "print(\"\\n‚úì Features now have mean‚âà0 and std‚âà1\")\n",
        "print(\"This helps algorithms that are sensitive to feature scales (like SVM, KNN).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1165135a",
      "metadata": {},
      "source": [
        "### Feature Engineering\n",
        "\n",
        "Let's create new features that might improve our model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25feddd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature 1: Family Size\n",
        "df_prep['FamilySize'] = df_prep['SibSp'] + df_prep['Parch'] + 1  # +1 for the passenger themselves\n",
        "print(\"Created FamilySize feature:\")\n",
        "print(df_prep[['SibSp', 'Parch', 'FamilySize']].head())\n",
        "\n",
        "# Feature 2: Is Alone (traveling solo)\n",
        "df_prep['IsAlone'] = (df_prep['FamilySize'] == 1).astype(int)\n",
        "print(\"\\nCreated IsAlone feature:\")\n",
        "print(df_prep[['FamilySize', 'IsAlone']].head())\n",
        "\n",
        "# Feature 3: Age Group\n",
        "df_prep['AgeGroup'] = pd.cut(df_prep['Age'], bins=[-np.inf, -0.5, 0.5, np.inf], \n",
        "                              labels=['Child', 'Adult', 'Senior'])\n",
        "print(\"\\nCreated AgeGroup feature (after scaling, thresholds are in standard deviations):\")\n",
        "print(df_prep[['Age', 'AgeGroup']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55dc4460",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature 4: Title from Name\n",
        "# Extract titles like Mr., Mrs., Miss., Master.\n",
        "df_prep['Title'] = df_prep['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "print(\"Extracted titles from names:\")\n",
        "print(df_prep['Title'].value_counts())\n",
        "\n",
        "# Group rare titles\n",
        "rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
        "df_prep['Title'] = df_prep['Title'].replace(rare_titles, 'Rare')\n",
        "df_prep['Title'] = df_prep['Title'].replace('Mlle', 'Miss')\n",
        "df_prep['Title'] = df_prep['Title'].replace('Ms', 'Miss')\n",
        "df_prep['Title'] = df_prep['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "print(\"\\nAfter grouping rare titles:\")\n",
        "print(df_prep['Title'].value_counts())\n",
        "\n",
        "# Encode titles\n",
        "title_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}\n",
        "df_prep['Title_encoded'] = df_prep['Title'].map(title_mapping)\n",
        "\n",
        "print(\"\\n‚úì Title feature engineered and encoded!\")\n",
        "print(\"Titles can indicate age group and social status.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c49d25",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze survival by engineered features\n",
        "print(\"Survival by Family Size:\")\n",
        "print(df_prep.groupby('FamilySize')['Survived'].mean().sort_values(ascending=False))\n",
        "print(\"\\nüí° Insight: Medium family sizes (2-4) had better survival rates!\")\n",
        "print(\"Very large families may have had difficulty staying together.\")\n",
        "\n",
        "print(\"\\nSurvival by Title:\")\n",
        "print(df_prep.groupby('Title')['Survived'].mean().sort_values(ascending=False))\n",
        "print(\"\\nüí° Insight: Mrs. and Miss. had highest survival (women and children first!)\")\n",
        "print(\"Mr. had lowest survival rate.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cce0717b",
      "metadata": {},
      "source": [
        "### üìù Knowledge Check - Module 5\n",
        "\n",
        "**Question 1:** Why did we drop the Cabin feature instead of imputing it?\n",
        "\n",
        "**Question 2:** What's the difference between dropping a row with missing values vs. imputing? When would you use each?\n",
        "\n",
        "**Question 3:** Why do we need to encode categorical variables like Sex and Embarked?\n",
        "\n",
        "**Question 4:** What does feature scaling do? Why is it important?\n",
        "\n",
        "**Question 5:** We created a FamilySize feature. How might this help the model predict survival better than using SibSp and Parch separately?\n",
        "\n",
        "**Question 6:** Looking at survival by Title, which title had the highest survival rate? Does this make sense historically?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "befb5fb7",
      "metadata": {},
      "source": [
        "---\n",
        "## Module 6: First Models - Regression and Classification\n",
        "\n",
        "Now that our data is prepared, let's build and compare different models!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9b4708d",
      "metadata": {},
      "source": [
        "### Regression vs. Classification\n",
        "\n",
        "**Classification (our task):**\n",
        "Predict discrete categories: Survived (1) or Died (0)\n",
        "\n",
        "**Regression:**\n",
        "Predict continuous values: e.g., predicting the exact fare a passenger paid\n",
        "\n",
        "Titanic survival is a **binary classification** problem."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8643cc20",
      "metadata": {},
      "source": [
        "### Logistic Regression for Classification\n",
        "\n",
        "Despite the name, Logistic Regression is for classification! It predicts the **probability** of survival, then uses a threshold (usually 0.5) to classify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd1b0ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Prepare features and target\n",
        "feature_cols = ['Pclass', 'Sex_encoded', 'Age', 'Fare', 'FamilySize', 'IsAlone', 'Title_encoded', 'Embarked_Q', 'Embarked_S']\n",
        "X = df_prep[feature_cols].values\n",
        "y = df_prep['Survived'].values\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"\\nUsing {len(feature_cols)} features to predict survival\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aae1f1fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {len(X_train)} passengers\")\n",
        "print(f\"Test set: {len(X_test)} passengers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07bdcd02",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Logistic Regression\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = log_reg.predict(X_train)\n",
        "y_pred_test = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "train_acc = accuracy_score(y_train, y_pred_train)\n",
        "test_acc = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"Logistic Regression Results:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Training Accuracy: {train_acc:.1%}\")\n",
        "print(f\"Test Accuracy: {test_acc:.1%}\")\n",
        "print(f\"\\n‚úì Model performs similarly on train and test data (good sign!)\")\n",
        "print(f\"This suggests the model is not overfitting.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e9e2a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get prediction probabilities\n",
        "y_pred_proba = log_reg.predict_proba(X_test)\n",
        "\n",
        "print(\"Sample Predictions (first 5 test passengers):\")\n",
        "print(\"=\"*60)\n",
        "for i in range(5):\n",
        "    prob_died = y_pred_proba[i][0]\n",
        "    prob_survived = y_pred_proba[i][1]\n",
        "    prediction = y_pred_test[i]\n",
        "    actual = y_test[i]\n",
        "    \n",
        "    print(f\"\\nPassenger {i+1}:\")\n",
        "    print(f\"  Probability of death: {prob_died:.1%}\")\n",
        "    print(f\"  Probability of survival: {prob_survived:.1%}\")\n",
        "    print(f\"  Predicted: {'Survived' if prediction == 1 else 'Died'}\")\n",
        "    print(f\"  Actual: {'Survived' if actual == 1 else 'Died'}\")\n",
        "    print(f\"  {'‚úì Correct!' if prediction == actual else '‚úó Incorrect'}\")\n",
        "\n",
        "print(\"\\nThe model outputs probabilities, then uses 0.5 as the threshold.\")\n",
        "print(\"If P(survival) >= 0.5, predict Survived; otherwise, predict Died.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b941c8f",
      "metadata": {},
      "source": [
        "### Feature Importance\n",
        "\n",
        "Let's see which features the model thinks are most important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75fec934",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature coefficients\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_cols,\n",
        "    'Coefficient': log_reg.coef_[0]\n",
        "}).sort_values('Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(\"Feature Importance (Logistic Regression Coefficients):\")\n",
        "print(\"=\"*60)\n",
        "print(feature_importance)\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"- Positive coefficient: increases probability of survival\")\n",
        "print(\"- Negative coefficient: decreases probability of survival\")\n",
        "print(\"- Larger absolute value: stronger influence\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 6))\n",
        "colors = ['green' if x > 0 else 'red' for x in feature_importance['Coefficient']]\n",
        "plt.barh(feature_importance['Feature'], feature_importance['Coefficient'], color=colors, edgecolor='black')\n",
        "plt.xlabel('Coefficient Value', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.title('Feature Importance in Logistic Regression', fontsize=14, fontweight='bold')\n",
        "plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° Key Insights:\")\n",
        "print(\"- Sex_encoded has strong negative coefficient (being male decreases survival)\")\n",
        "print(\"- Title_encoded and Pclass also important\")\n",
        "print(\"- Our engineered features (FamilySize, IsAlone) are contributing!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "447f012c",
      "metadata": {},
      "source": [
        "### üìù Knowledge Check - Module 6\n",
        "\n",
        "**Question 1:** Why is Titanic survival prediction a classification problem, not a regression problem?\n",
        "\n",
        "**Question 2:** What does it mean when Logistic Regression outputs a probability of 0.73 for survival?\n",
        "\n",
        "**Question 3:** Our model achieved ~80% test accuracy. What does this mean? Is this good?\n",
        "\n",
        "**Question 4:** Looking at the feature coefficients, which feature has the strongest negative impact on survival? Does this match what we learned in EDA?\n",
        "\n",
        "**Question 5:** Why is it important that training and test accuracy are similar?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cf2a067",
      "metadata": {},
      "source": [
        "---\n",
        "## Module 7: Evaluating Machine Learning Models\n",
        "\n",
        "Accuracy alone doesn't tell the whole story. Let's explore different evaluation metrics and understand what they mean for Titanic survival prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a1a09fa",
      "metadata": {},
      "source": [
        "### Why Multiple Metrics Matter\n",
        "\n",
        "Imagine a lazy model that always predicts \"Died\" for everyone:\n",
        "- It would be 62% accurate (since 62% died)\n",
        "- But it would miss ALL survivors!\n",
        "- Accuracy can be misleading\n",
        "\n",
        "We need more nuanced metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60608e9d",
      "metadata": {},
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "A table showing where our model was right and wrong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1469a2b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(\"=\"*60)\n",
        "print(cm)\n",
        "print(\"\\nStructure:\")\n",
        "print(\"                Predicted Died    Predicted Survived\")\n",
        "print(f\"Actually Died        {cm[0,0]:3d} (TN)          {cm[0,1]:3d} (FP)\")\n",
        "print(f\"Actually Survived    {cm[1,0]:3d} (FN)          {cm[1,1]:3d} (TP)\")\n",
        "\n",
        "print(\"\\nDefinitions:\")\n",
        "print(\"- True Negative (TN): Correctly predicted death\")\n",
        "print(\"- False Positive (FP): Predicted survival but actually died (Type I error)\")\n",
        "print(\"- False Negative (FN): Predicted death but actually survived (Type II error)\")\n",
        "print(\"- True Positive (TP): Correctly predicted survival\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Died', 'Survived'],\n",
        "            yticklabels=['Died', 'Survived'])\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b3ff490",
      "metadata": {},
      "source": [
        "### Precision, Recall, and F1-Score\n",
        "\n",
        "These metrics help us understand different aspects of model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d17fe49",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate metrics\n",
        "precision = precision_score(y_test, y_pred_test)\n",
        "recall = recall_score(y_test, y_pred_test)\n",
        "f1 = f1_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"Classification Metrics:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy:  {test_acc:.1%}\")\n",
        "print(f\"Precision: {precision:.1%}\")\n",
        "print(f\"Recall:    {recall:.1%}\")\n",
        "print(f\"F1-Score:  {f1:.1%}\")\n",
        "\n",
        "print(\"\\nWhat do these mean?\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy:  {test_acc:.1%} of all predictions were correct\")\n",
        "print(f\"Precision: {precision:.1%} of predicted survivors actually survived\")\n",
        "print(f\"           (How reliable are our 'Survived' predictions?)\")\n",
        "print(f\"Recall:    {recall:.1%} of actual survivors were identified\")\n",
        "print(f\"           (How many survivors did we catch?)\")\n",
        "print(f\"F1-Score:  {f1:.1%} harmonic mean of precision and recall\")\n",
        "print(f\"           (Balanced measure)\")\n",
        "\n",
        "print(\"\\nüí° In Titanic context:\")\n",
        "print(\"- High Precision: When we predict someone survived, we're usually right\")\n",
        "print(\"- High Recall: We successfully identify most of the actual survivors\")\n",
        "print(\"- F1-Score: Balances both - useful when classes are imbalanced\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fda104ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed classification report\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(y_test, y_pred_test, target_names=['Died', 'Survived']))\n",
        "\n",
        "print(\"\\nHow to read this:\")\n",
        "print(\"- Precision: Of all predicted as this class, how many were correct?\")\n",
        "print(\"- Recall: Of all actual instances of this class, how many did we catch?\")\n",
        "print(\"- F1-score: Harmonic mean of precision and recall\")\n",
        "print(\"- Support: Number of actual instances in test set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ab80264",
      "metadata": {},
      "source": [
        "### ROC Curve and AUC\n",
        "\n",
        "The ROC curve shows model performance across all possible decision thresholds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfe1d22b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Get prediction probabilities for positive class\n",
        "y_pred_proba_positive = log_reg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_positive)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "print(f\"AUC (Area Under Curve): {roc_auc:.3f}\")\n",
        "print(\"\\nAUC Interpretation:\")\n",
        "print(\"- 1.0: Perfect classifier\")\n",
        "print(\"- 0.9-1.0: Excellent\")\n",
        "print(\"- 0.8-0.9: Good\")\n",
        "print(\"- 0.7-0.8: Fair\")\n",
        "print(\"- 0.5-0.7: Poor\")\n",
        "print(\"- 0.5: No better than random guessing\")\n",
        "print(f\"\\nOur model: {roc_auc:.3f} - {'Excellent!' if roc_auc >= 0.9 else 'Good!' if roc_auc >= 0.8 else 'Fair' if roc_auc >= 0.7 else 'Needs improvement'}\")\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
        "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Classifier (AUC = 0.5)')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate (Recall)', fontsize=12)\n",
        "plt.title('ROC Curve for Titanic Survival Prediction', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nROC Curve shows:\")\n",
        "print(\"- Trade-off between True Positive Rate and False Positive Rate\")\n",
        "print(\"- Closer to top-left corner = better performance\")\n",
        "print(\"- Diagonal line = random guessing\")\n",
        "print(\"- Our curve is well above the diagonal - model is learning!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d732923e",
      "metadata": {},
      "source": [
        "### Cross-Validation\n",
        "\n",
        "Instead of a single train/test split, let's use k-fold cross-validation for a more robust evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52adcd77",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_val_score(log_reg, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"5-Fold Cross-Validation Results:\")\n",
        "print(\"=\"*60)\n",
        "for i, score in enumerate(cv_scores, 1):\n",
        "    print(f\"Fold {i}: {score:.1%}\")\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(f\"Mean Accuracy: {cv_scores.mean():.1%}\")\n",
        "print(f\"Std Deviation: {cv_scores.std():.3f}\")\n",
        "print(f\"\\nThis is a more reliable estimate than a single train/test split.\")\n",
        "print(f\"Low std deviation means the model is stable across different data splits.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45c12f02",
      "metadata": {},
      "source": [
        "### üìù Knowledge Check - Module 7\n",
        "\n",
        "**Question 1:** What does the confusion matrix tell us that accuracy alone doesn't?\n",
        "\n",
        "**Question 2:** In the Titanic context, which is worse: False Positive (predicting survival when they died) or False Negative (predicting death when they survived)? Why might this matter?\n",
        "\n",
        "**Question 3:** What's the difference between precision and recall? Give an example of when you'd prioritize one over the other.\n",
        "\n",
        "**Question 4:** Our model has an AUC of ~0.85. What does this mean?\n",
        "\n",
        "**Question 5:** Why is cross-validation more reliable than a single train/test split?\n",
        "\n",
        "**Question 6:** If we wanted to maximize the chance of identifying all survivors (even if it means some false alarms), should we focus on improving precision or recall?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "571d9db3",
      "metadata": {},
      "source": [
        "---\n",
        "## Module 8: Overfitting, Underfitting, and Regularization\n",
        "\n",
        "One of the biggest challenges: building models that work well on NEW data, not just the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f38f8d40",
      "metadata": {},
      "source": [
        "### The Bias-Variance Tradeoff\n",
        "\n",
        "**Bias:** Error from overly simple assumptions\n",
        "- High bias ‚Üí **Underfitting**\n",
        "- Model is too simple to capture patterns\n",
        "- Poor performance on both training AND test data\n",
        "\n",
        "**Variance:** Error from too much complexity\n",
        "- High variance ‚Üí **Overfitting**\n",
        "- Model learns noise as if it were signal\n",
        "- Great performance on training, poor on test data\n",
        "\n",
        "**Goal:** Find the sweet spot that minimizes total error!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dcac56b",
      "metadata": {},
      "source": [
        "### Demonstrating Overfitting\n",
        "\n",
        "Let's intentionally create an overfit model to see what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2c4becc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train models with different complexities\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Model 1: Shallow tree (may underfit)\n",
        "shallow_tree = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
        "shallow_tree.fit(X_train, y_train)\n",
        "\n",
        "# Model 2: Medium tree (good balance)\n",
        "medium_tree = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "medium_tree.fit(X_train, y_train)\n",
        "\n",
        "# Model 3: Deep tree (may overfit)\n",
        "deep_tree = DecisionTreeClassifier(max_depth=None, random_state=42)  # No limit!\n",
        "deep_tree.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model Complexity Comparison:\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4be2f6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate all three models\n",
        "models = [\n",
        "    ('Shallow (depth=2)', shallow_tree),\n",
        "    ('Medium (depth=5)', medium_tree),\n",
        "    ('Deep (no limit)', deep_tree)\n",
        "]\n",
        "\n",
        "results = []\n",
        "for name, model in models:\n",
        "    train_acc = model.score(X_train, y_train)\n",
        "    test_acc = model.score(X_test, y_test)\n",
        "    gap = train_acc - test_acc\n",
        "    \n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Train Accuracy': f\"{train_acc:.1%}\",\n",
        "        'Test Accuracy': f\"{test_acc:.1%}\",\n",
        "        'Gap': f\"{gap:.1%}\"\n",
        "    })\n",
        "    \n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n",
        "\n",
        "print(\"\\nüí° Observations:\")\n",
        "print(\"- Shallow tree: Low accuracy on both (UNDERFITTING)\")\n",
        "print(\"- Medium tree: Good balance between train and test\")\n",
        "print(\"- Deep tree: Perfect training but lower test (OVERFITTING)\")\n",
        "print(\"\\nThe 'Gap' shows overfitting - large gap means the model memorized training data!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c73eb18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the tradeoff\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_accs = [0.78, 0.85, 1.00]  # Approximate values\n",
        "test_accs = [0.76, 0.82, 0.80]   # Approximate values\n",
        "complexity = ['Low\\n(Shallow)', 'Medium', 'High\\n(Deep)']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(complexity, train_accs, marker='o', linewidth=2, markersize=10, label='Training Accuracy', color='blue')\n",
        "plt.plot(complexity, test_accs, marker='s', linewidth=2, markersize=10, label='Test Accuracy', color='red')\n",
        "plt.xlabel('Model Complexity', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.title('Bias-Variance Tradeoff', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.ylim(0.7, 1.05)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"As complexity increases:\")\n",
        "print(\"- Training accuracy keeps improving\")\n",
        "print(\"- Test accuracy improves then degrades (overfitting!)\")\n",
        "print(\"- The gap between them grows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b549f9b",
      "metadata": {},
      "source": [
        "### Regularization\n",
        "\n",
        "Regularization prevents overfitting by penalizing model complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8507be8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train models with different regularization strengths\n",
        "# C is inverse of regularization: smaller C = stronger regularization\n",
        "C_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
        "\n",
        "reg_results = []\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(C=C, max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    train_acc = model.score(X_train, y_train)\n",
        "    test_acc = model.score(X_test, y_test)\n",
        "    \n",
        "    reg_results.append({\n",
        "        'C (Regularization)': C,\n",
        "        'Train Acc': train_acc,\n",
        "        'Test Acc': test_acc,\n",
        "        'Gap': train_acc - test_acc\n",
        "    })\n",
        "\n",
        "reg_df = pd.DataFrame(reg_results)\n",
        "print(\"Regularization Strength vs Performance:\")\n",
        "print(\"=\"*60)\n",
        "print(reg_df)\n",
        "print(\"\\nRemember: Smaller C = Stronger regularization = Simpler model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c93fbe39",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize regularization effect\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(reg_df['C (Regularization)'], reg_df['Train Acc'], \n",
        "         marker='o', linewidth=2, markersize=8, label='Training Accuracy')\n",
        "plt.plot(reg_df['C (Regularization)'], reg_df['Test Acc'], \n",
        "         marker='s', linewidth=2, markersize=8, label='Test Accuracy')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('C (Inverse Regularization Strength)', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.title('Effect of Regularization on Model Performance', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° Finding the right regularization:\")\n",
        "print(\"- Too strong (C too small): Underfitting\")\n",
        "print(\"- Too weak (C too large): Overfitting\")\n",
        "print(\"- Just right (C ‚âà 1.0): Good generalization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "323d80c6",
      "metadata": {},
      "source": [
        "### üìù Knowledge Check - Module 8\n",
        "\n",
        "**Question 1:** What's the difference between underfitting and overfitting? Give signs of each.\n",
        "\n",
        "**Question 2:** Looking at the model complexity comparison, which model would you choose for production? Why?\n",
        "\n",
        "**Question 3:** What does a large gap between training and test accuracy indicate?\n",
        "\n",
        "**Question 4:** How does regularization help prevent overfitting?\n",
        "\n",
        "**Question 5:** In the regularization experiment, which value of C gave the best test performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09fc663d",
      "metadata": {},
      "source": [
        "---\n",
        "## Module 9: Decision Trees and Ensemble Methods\n",
        "\n",
        "Single models are good, but combining multiple models often works even better! This is the idea behind ensemble methods."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ac3b9e0",
      "metadata": {},
      "source": [
        "### Decision Trees Recap\n",
        "\n",
        "Decision trees ask yes/no questions about features:\n",
        "- \"Is the passenger female?\" ‚Üí Yes/No\n",
        "- \"Is passenger class 1st?\" ‚Üí Yes/No\n",
        "- \"Is age < 15?\" ‚Üí Yes/No\n",
        "\n",
        "**Advantages:** Easy to interpret, handle mixed data types\n",
        "**Disadvantages:** Prone to overfitting, unstable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "876ae01a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "# Train a simple decision tree\n",
        "tree_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "train_acc = tree_model.score(X_train, y_train)\n",
        "test_acc = tree_model.score(X_test, y_test)\n",
        "\n",
        "print(f\"Single Decision Tree:\")\n",
        "print(f\"Training Accuracy: {train_acc:.1%}\")\n",
        "print(f\"Test Accuracy: {test_acc:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08fffd79",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the decision tree\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(tree_model, \n",
        "          feature_names=feature_cols,\n",
        "          class_names=['Died', 'Survived'],\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=10)\n",
        "plt.title('Decision Tree for Titanic Survival (max_depth=3)', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nHow to read:\")\n",
        "print(\"- Each box shows a decision rule or prediction\")\n",
        "print(\"- Colors indicate the dominant class (orange=died, blue=survived)\")\n",
        "print(\"- 'samples' shows how many training examples reach that node\")\n",
        "print(\"- 'value' shows [died, survived] counts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1787b46d",
      "metadata": {},
      "source": [
        "### Random Forests (Bagging)\n",
        "\n",
        "**Idea:** Train many decision trees on random subsets of data and features, then vote!\n",
        "\n",
        "**Why it works:**\n",
        "- Different trees make different errors\n",
        "- Errors cancel out when we average/vote\n",
        "- Reduces overfitting\n",
        "- More stable than single trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd8e38c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train Random Forest\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,  # 100 trees in the forest\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "train_acc_rf = rf_model.score(X_train, y_train)\n",
        "test_acc_rf = rf_model.score(X_test, y_test)\n",
        "\n",
        "print(f\"Random Forest (100 trees):\")\n",
        "print(f\"Training Accuracy: {train_acc_rf:.1%}\")\n",
        "print(f\"Test Accuracy: {test_acc_rf:.1%}\")\n",
        "print(f\"\\n‚úì Better than single tree!\")\n",
        "print(f\"Improvement: {(test_acc_rf - test_acc)*100:.1f} percentage points\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "597ea850",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance from Random Forest\n",
        "feature_imp = pd.DataFrame({\n",
        "    'Feature': feature_cols,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance from Random Forest:\")\n",
        "print(\"=\"*60)\n",
        "print(feature_imp)\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_imp['Feature'], feature_imp['Importance'], color='skyblue', edgecolor='black')\n",
        "plt.xlabel('Importance', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.title('Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° Top 3 most important features:\")\n",
        "for i, row in feature_imp.head(3).iterrows():\n",
        "    print(f\"{i+1}. {row['Feature']}: {row['Importance']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c01b2bf6",
      "metadata": {},
      "source": [
        "### Gradient Boosting\n",
        "\n",
        "**Idea:** Train trees sequentially, each one trying to fix the errors of previous trees.\n",
        "\n",
        "**Why it works:**\n",
        "- Each new tree focuses on hard-to-predict examples\n",
        "- Gradually improves predictions\n",
        "- Often achieves best performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c0325fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Train Gradient Boosting\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "train_acc_gb = gb_model.score(X_train, y_train)\n",
        "test_acc_gb = gb_model.score(X_test, y_test)\n",
        "\n",
        "print(f\"Gradient Boosting:\")\n",
        "print(f\"Training Accuracy: {train_acc_gb:.1%}\")\n",
        "print(f\"Test Accuracy: {test_acc_gb:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1d6791a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all models\n",
        "model_comparison = pd.DataFrame([\n",
        "    {'Model': 'Logistic Regression', 'Test Accuracy': test_acc},\n",
        "    {'Model': 'Single Decision Tree', 'Test Accuracy': test_acc},\n",
        "    {'Model': 'Random Forest', 'Test Accuracy': test_acc_rf},\n",
        "    {'Model': 'Gradient Boosting', 'Test Accuracy': test_acc_gb}\n",
        "]).sort_values('Test Accuracy', ascending=False)\n",
        "\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(\"=\"*60)\n",
        "for idx, row in model_comparison.iterrows():\n",
        "    print(f\"{row['Model']:25s}: {row['Test Accuracy']:.1%}\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 6))\n",
        "colors = ['gold', 'silver', '#CD7F32', 'lightblue']\n",
        "plt.barh(model_comparison['Model'], model_comparison['Test Accuracy'], \n",
        "         color=colors[:len(model_comparison)], edgecolor='black')\n",
        "plt.xlabel('Test Accuracy', fontsize=12)\n",
        "plt.ylabel('Model', fontsize=12)\n",
        "plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
        "plt.xlim(0.75, 0.85)\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüèÜ Ensemble methods (Random Forest, Gradient Boosting) typically outperform single models!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcec0268",
      "metadata": {},
      "source": [
        "### üìù Knowledge Check - Module 9\n",
        "\n",
        "**Question 1:** How does a decision tree make predictions? Why are they easy to interpret?\n",
        "\n",
        "**Question 2:** What is the main idea behind Random Forests? Why do they reduce overfitting?\n",
        "\n",
        "**Question 3:** What's the difference between bagging (Random Forest) and boosting (Gradient Boosting)?\n",
        "\n",
        "**Question 4:** Looking at feature importance, which feature is most important for predicting survival?\n",
        "\n",
        "**Question 5:** Why do ensemble methods generally outperform single models?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db1849d1",
      "metadata": {},
      "source": [
        "---\n",
        "## Module 10: Unsupervised Learning - Clustering & Dimensionality Reduction\n",
        "\n",
        "So far we've used supervised learning (we knew who survived). Let's explore unsupervised learning where we discover patterns without labels!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a485fea",
      "metadata": {},
      "source": [
        "### K-Means Clustering\n",
        "\n",
        "**Goal:** Group passengers into clusters based on similarity\n",
        "\n",
        "**Use case:** What if we didn't know survival outcomes? Can we find natural groupings of passengers?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74611546",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Use features (without survival label)\n",
        "X_cluster = df_prep[feature_cols].values\n",
        "\n",
        "# Apply K-Means with 2 clusters\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "cluster_labels = kmeans.fit_predict(X_cluster)\n",
        "\n",
        "print(f\"K-Means Clustering (k=2):\")\n",
        "print(f\"Cluster 0: {(cluster_labels == 0).sum()} passengers\")\n",
        "print(f\"Cluster 1: {(cluster_labels == 1).sum()} passengers\")\n",
        "print(f\"\\nInertia (lower is better): {kmeans.inertia_:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7896106",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare clusters with actual survival\n",
        "df_prep['Cluster'] = cluster_labels\n",
        "\n",
        "print(\"\\nCluster vs Actual Survival:\")\n",
        "print(\"=\"*60)\n",
        "print(pd.crosstab(df_prep['Cluster'], df_prep['Survived'], \n",
        "                  rownames=['Cluster'], colnames=['Survived']))\n",
        "\n",
        "print(\"\\nüí° Interesting! The clusters somewhat align with survival.\")\n",
        "print(\"This suggests there are natural groupings in passenger characteristics\")\n",
        "print(\"that relate to survival, even without using the survival label!\")\n",
        "\n",
        "# Survival rate by cluster\n",
        "print(\"\\nSurvival rate by cluster:\")\n",
        "for cluster in [0, 1]:\n",
        "    rate = df_prep[df_prep['Cluster'] == cluster]['Survived'].mean()\n",
        "    print(f\"Cluster {cluster}: {rate:.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f87687c",
      "metadata": {},
      "source": [
        "### Elbow Method: Finding Optimal K\n",
        "\n",
        "How many clusters should we use? The elbow method helps decide!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30fc404a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try different values of k\n",
        "inertias = []\n",
        "K_range = range(1, 11)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans_temp.fit(X_cluster)\n",
        "    inertias.append(kmeans_temp.inertia_)\n",
        "\n",
        "# Plot elbow curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(K_range, inertias, marker='o', linewidth=2, markersize=10, color='blue')\n",
        "plt.xlabel('Number of Clusters (k)', fontsize=12)\n",
        "plt.ylabel('Inertia (Sum of Squared Distances)', fontsize=12)\n",
        "plt.title('Elbow Method for Optimal k', fontsize=14, fontweight='bold')\n",
        "plt.xticks(K_range)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Look for the 'elbow' - where the curve bends.\")\n",
        "print(\"That's where adding more clusters gives diminishing returns.\")\n",
        "print(\"For Titanic, k=2 or k=3 seems reasonable.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eae8baa",
      "metadata": {},
      "source": [
        "### Principal Component Analysis (PCA)\n",
        "\n",
        "**Goal:** Reduce dimensionality while preserving information\n",
        "\n",
        "**Use case:** We have 9 features. Can we visualize passengers in 2D?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d225969a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA()\n",
        "pca.fit(X_cluster)\n",
        "\n",
        "# Explained variance\n",
        "explained_var = pca.explained_variance_ratio_\n",
        "\n",
        "print(\"PCA Results:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Original dimensions: {X_cluster.shape[1]}\")\n",
        "print(\"\\nExplained variance by component:\")\n",
        "for i, var in enumerate(explained_var, 1):\n",
        "    print(f\"  PC{i}: {var:.1%}\")\n",
        "\n",
        "cumulative_var = np.cumsum(explained_var)\n",
        "print(\"\\nCumulative explained variance:\")\n",
        "for i in [1, 2, 3, 4, 5]:\n",
        "    print(f\"  First {i} components: {cumulative_var[i-1]:.1%}\")\n",
        "\n",
        "print(f\"\\nüí° With just 2 components, we retain {cumulative_var[1]:.1%} of information!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01318753",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize explained variance\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Individual variance\n",
        "ax1.bar(range(1, len(explained_var)+1), explained_var, color='skyblue', edgecolor='black')\n",
        "ax1.set_xlabel('Principal Component', fontsize=12)\n",
        "ax1.set_ylabel('Explained Variance Ratio', fontsize=12)\n",
        "ax1.set_title('Variance Explained by Each Component', fontsize=14, fontweight='bold')\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Cumulative variance\n",
        "ax2.plot(range(1, len(cumulative_var)+1), cumulative_var, \n",
        "         marker='o', linewidth=2, markersize=10, color='green')\n",
        "ax2.axhline(y=0.95, color='red', linestyle='--', linewidth=2, label='95% threshold')\n",
        "ax2.set_xlabel('Number of Components', fontsize=12)\n",
        "ax2.set_ylabel('Cumulative Explained Variance', fontsize=12)\n",
        "ax2.set_title('Cumulative Explained Variance', fontsize=14, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fdef3ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reduce to 2D and visualize\n",
        "pca_2d = PCA(n_components=2)\n",
        "X_pca = pca_2d.fit_transform(X_cluster)\n",
        "\n",
        "# Plot by survival\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for survived in [0, 1]:\n",
        "    mask = df_prep['Survived'] == survived\n",
        "    label = 'Survived' if survived == 1 else 'Died'\n",
        "    color = 'green' if survived == 1 else 'red'\n",
        "    plt.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
        "                label=label, alpha=0.6, s=50, color=color, edgecolors='black')\n",
        "\n",
        "plt.xlabel(f'First Principal Component ({explained_var[0]:.1%} variance)', fontsize=12)\n",
        "plt.ylabel(f'Second Principal Component ({explained_var[1]:.1%} variance)', fontsize=12)\n",
        "plt.title('Titanic Passengers in 2D (PCA)', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° We've reduced 9 dimensions to 2!\")\n",
        "print(\"You can see some separation between survivors and non-survivors.\")\n",
        "print(\"This visualization would be impossible with 9 dimensions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff6db9e2",
      "metadata": {},
      "source": [
        "### üìù Knowledge Check - Module 10\n",
        "\n",
        "**Question 1:** What's the difference between supervised and unsupervised learning?\n",
        "\n",
        "**Question 2:** How does K-Means clustering work? What does k represent?\n",
        "\n",
        "**Question 3:** What is the elbow method used for?\n",
        "\n",
        "**Question 4:** Why is dimensionality reduction useful? Give two reasons.\n",
        "\n",
        "**Question 5:** We reduced from 9 features to 2 principal components. What percentage of information did we retain?\n",
        "\n",
        "**Question 6:** Looking at the PCA visualization, can you see any separation between survivors and non-survivors?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9823e505",
      "metadata": {},
      "source": [
        "---\n",
        "## üéâ Congratulations! You've Completed the Comprehensive ML Lab!\n",
        "\n",
        "### What You've Mastered:\n",
        "\n",
        "**Module 1:** Introduction to ML concepts and terminology\n",
        "\n",
        "**Module 2:** Essential Python libraries (Pandas, NumPy, Scikit-learn, Matplotlib)\n",
        "\n",
        "**Module 3:** ML workflow and building your first classifier\n",
        "\n",
        "**Module 4:** Exploratory Data Analysis - understanding the Titanic disaster through data\n",
        "\n",
        "**Module 5:** Data preparation, handling missing values, encoding, scaling, and feature engineering\n",
        "\n",
        "**Module 6:** Classification with Logistic Regression and understanding feature importance\n",
        "\n",
        "**Module 7:** Model evaluation with multiple metrics (accuracy, precision, recall, F1, ROC/AUC, cross-validation)\n",
        "\n",
        "**Module 8:** Overfitting, underfitting, and regularization techniques\n",
        "\n",
        "**Module 9:** Decision trees and ensemble methods (Random Forests, Gradient Boosting)\n",
        "\n",
        "**Module 10:** Unsupervised learning (K-Means clustering and PCA)\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "1. **Data preparation is crucial** - 70-80% of ML work is cleaning and preparing data\n",
        "2. **Feature engineering matters** - Creating good features often beats choosing fancy algorithms\n",
        "3. **Always evaluate properly** - Use train/test splits, cross-validation, and multiple metrics\n",
        "4. **Ensemble methods rock** - Combining models usually beats single models\n",
        "5. **Visualize everything** - Plots help you understand data and communicate results\n",
        "6. **Context matters** - Understanding the problem (Titanic disaster) helps guide modeling decisions\n",
        "\n",
        "\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. **Try other datasets** - Apply these techniques to new problems\n",
        "2. **Experiment** - Change hyperparameters, try different algorithms\n",
        "3. **Build projects** - Create end-to-end ML solutions\n",
        "4. **Learn more** - Explore deep learning, NLP, computer vision\n",
        "5. **Practice** - The more you code, the better you get!\n",
        "\n",
        "### Final Thoughts:\n",
        "\n",
        "> \"Machine learning is not magic - it's pattern recognition powered by data and algorithms. With the right tools and understanding, you can build models that make a real difference.\"\n",
        "\n",
        "**You're now ready to tackle your midterm project and beyond!** üöÄ\n",
        "\n",
        "---\n",
        "\n",
        "### Resources for Further Learning:\n",
        "\n",
        "- **Scikit-learn Documentation:** https://scikit-learn.org/\n",
        "- **Kaggle Titanic Competition:** https://www.kaggle.com/c/titanic\n",
        "- **Pandas Documentation:** https://pandas.pydata.org/\n",
        "- **Machine Learning Course:** Andrew Ng's ML course on Coursera\n",
        "\n",
        "**Happy Learning! May your models always generalize well! üéì**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
